{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/ens_slide_1.png\" width=\"700\" height=\"700\">\n",
    "\n",
    "<img src=\"Images/ens_slide_2.png\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods \n",
    "\n",
    "Ensemble Methods are machine learning algorithms that rely on the \"Wisdom of the Crowd\"\n",
    "\n",
    "Many weak algorithms working together do better than 1 big, monolithic algorithm\n",
    "\n",
    "They are two major groups for ensemble methods: **Random Forests** and **Gradient Boosted Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest is a name for a type of supervised learning\n",
    "\n",
    "***Random Forest*** is just a collection of many small ***Decision Trees***\n",
    "\n",
    "Assume we have a dataset with 10 columns, and thousands of rows. The Random forest algorithm would start by randomly selecting around 2/3 of the rows, and then randomly selecting 6 columns in the data \n",
    "\n",
    "<img src=\"Images/random_forest.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity: Apply Random Forest to iris dataset \n",
    "\n",
    "Read : https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "\n",
    "Finish the turorial on your own, and then answer the following questions:\n",
    "\n",
    "- What was the feature importance as described in the tutorial: `clf.feature_importances_`\n",
    "\n",
    "- Change number of estimator (`n_estimators`) and compare the accuracy result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "In boosting, the trees are built sequentially such that each subsequent tree aims to reduce the errors of the previous tree\n",
    "\n",
    "The tree that grows next in the sequence **will learn from an updated version of the residuals**\n",
    "\n",
    "- Residuals: The differences between observed and predicted values of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: We want to build a model for a prediction problem with Boosting method\n",
    "\n",
    "- Consider the following data, where the years of experience is predictor variable (feature) and salary (in thousand dollars) is the target\n",
    "\n",
    "<img src=\"Images/dataset_boosting.png\" width=\"150\" height=\"150\">\n",
    "\n",
    "- Using regression trees as base learners, we can create a model to predict the salary\n",
    "\n",
    "- As the first step, obtain the mean value of target: `F0 = np.mean(Y)` \n",
    "\n",
    "- Now build the simplest decision tree regressor with the Feature as `X` and `Y-F0` as the target: Below is the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "# Feature, years of work experience\n",
    "X = np.array([5, 7, 12, 23, 25, 28, 29, 34, 35, 40])\n",
    "# Target, salary in in thousand dollars\n",
    "Y = np.array([82, 80, 103, 118, 172, 127, 204, 189, 99, 166])\n",
    "\n",
    "# Compute the mean of target and subtract from target\n",
    "F0 = np.mean(Y)\n",
    "#print(F0)\n",
    "\n",
    "# Build and train the simple Regression Model with DT\n",
    "regre = DecisionTreeRegressor(max_depth=1)\n",
    "regre.fit(X.reshape(-1, 1), (Y-F0).reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Draw graph\n",
    "dot_data = export_graphviz(regre)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_png('simple_reg_tree_step1.png')\n",
    "\n",
    "# pydot_graph = pydotplus.graph_from_dot_data(regre)\n",
    "# pydot_graph.write_png('original_tree.png')\n",
    "# pydot_graph.set_size('\"11,12!\"')\n",
    "# pydot_graph.write_png('resized_tree.png')\n",
    "# gvz_graph = graphviz.Source(pydot_graph.to_string())\n",
    "# gvz_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As the second step: obtain `h1` as the output result of decision tree regressor with `X` as input : `F1 =F0 + h1` \n",
    "\n",
    "- As the third step: build another simple decision tree regressor with Salary as `X` and `Y-F1` as the target\n",
    "\n",
    "- Keep doing these steps we can predict salary, `Y` from years of experience `X` \n",
    "\n",
    "<img src=\"Images/visualization_boosting.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11ed96790>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iteratively predict Y from X using Boosting method\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature, years of work experience\n",
    "X = np.array([5, 7, 12, 23, 25, 28, 29, 34, 35, 40])\n",
    "# Target, salary in in thousand dollars\n",
    "Y = np.array([82, 80, 103, 118, 172, 127, 204, 189, 99, 166])\n",
    "\n",
    "iteration = 3 # years of experience\n",
    "F = np.zeros((iteration+1, len(Y)))\n",
    "for i in range(iteration):\n",
    "    if i == 0:\n",
    "        F[i] = np.mean(Y)\n",
    "    regre = DecisionTreeRegressor(max_depth=1)\n",
    "    regre.fit(X.reshape(-1, 1), (Y-F[i]).reshape(-1, 1))\n",
    "    # h[i] = regre.predict(X.reshape(-1, 1)), we do not need to define separate variable for h\n",
    "    F[i+1] = F[i] + regre.predict(X.reshape(-1, 1))\n",
    "    \n",
    "#F.shape, Y.shape    \n",
    "\n",
    "plt.plot(X, F[-1])\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared:  0.708028219123793\n",
      "mean squared error 540.2645833333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "r2 = r2_score(Y,F[-1])\n",
    "rmse = np.sqrt(mean_squared_error(Y, F[-1])) # different b/w what we actually have and squares of errors\n",
    "mse = mean_squared_error(Y, F[-1])\n",
    "print('r-squared: ',r2)\n",
    "print('mean squared error', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Demonstrating the Potential of Boosting*** : https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/\n",
    "\n",
    "## Optional: Pseudocode of Boosting Algorithm:\n",
    "\n",
    "<img src=\"Images/boosting_algorithm.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost\n",
    "\n",
    "XGBoost is short for eXtreme Gradient Boosting. It is\n",
    "\n",
    "· An open-sourced tool\n",
    "\n",
    "    - Computation in C++\n",
    "    \n",
    "    - R/python/Julia interface provided\n",
    "    \n",
    "· A variant of the gradient boosting machine \n",
    "\n",
    "    - Tree-based model\n",
    "    \n",
    "· The winning model for several kaggle competitions\n",
    "\n",
    "Apply Xgboost to boston housing dataset (https://www.datacamp.com/community/tutorials/xgboost-in-python)\n",
    "\n",
    "Plot the feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Reading: XGBoost's hyperparameters\n",
    "\n",
    "At this point, before building the model, you should be aware of the tuning parameters that XGBoost provides. Well, there are a plethora of tuning parameters for tree-based learners in XGBoost and you can read all about them here. But the most common ones that you should know are:\n",
    "\n",
    "***learning_rate***: step size shrinkage used to prevent overfitting. Range is [0,1]\n",
    "\n",
    "***max_depth***: determines how deeply each tree is allowed to grow during any boosting round.\n",
    "\n",
    "***subsample***: percentage of samples used per tree. Low value can lead to underfitting.\n",
    "\n",
    "***colsample_bytree***: percentage of features used per tree. High value can lead to overfitting.\n",
    "\n",
    "***n_estimators***: number of trees you want to build.\n",
    "\n",
    "***objective***: determines the loss function to be used like reg:linear for regression problems, reg:logistic for classification problems with only decision, binary:logistic for classification problems with probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Ensemble Methods are machine learning algorithms that rely on the \"Wisdom of the Crowd\"\n",
    "\n",
    "- Many weak algorithms working together do better than 1 big, monolithic algorithm\n",
    "\n",
    "- In boosting, each tree will learn from an updated version of the residuals\n",
    "\n",
    "- They are two major groups for ensemble methods:\n",
    "\n",
    "    - Random Forests \n",
    "    \n",
    "    - Gradient Boosted Trees\n",
    "\n",
    "- The Ensemble methods are able to obtain and rank the feature importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "- https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "    \n",
    "- https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/\n",
    "\n",
    "- https://www.datacamp.com/community/tutorials/xgboost-in-python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
