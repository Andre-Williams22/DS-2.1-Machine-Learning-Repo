{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 375   57  245 1472  105   54  193  147 1102  720  253  685  488  198\n",
      "   360 1374  156]\n",
      " [ 135   47  267 1494   66   41  209   93  674 1033  143  586  355  187\n",
      "   334 1506  139]\n",
      " [ 458   53  242 1462  103   62  184  122  957  566  171  750  418  220\n",
      "   337 1572  147]\n",
      " [ 475   73  227 1582  103   64  235  160 1137  874  265  803  570  203\n",
      "   365 1256  175]]\n",
      "[[-144.99315218   -2.53299944]\n",
      " [ 477.39163882  -58.90186182]\n",
      " [ -91.869339    286.08178613]\n",
      " [-240.52914764 -224.64692488]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "# use pandas to read in the excel spreadsheet\n",
    "df = pd.read_excel('Datasets/pca_uk.xlsx')\n",
    "\n",
    "# build a matrix of the feature values, not including the text labels\n",
    "X = np.array([df[i].values for i in df.columns if i != 'Features'])\n",
    "\n",
    "print(X)\n",
    "\n",
    "# calculate the PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Find the principle components of 17 features\n",
    "X_r = pca.fit_transform(X)\n",
    "\n",
    "print(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets visualize the principle components\n",
    "\n",
    "for feature, (plot_x,plot_y) in enumerate(zip(X_r[:, 0], X_r[:, 1])):\n",
    "    plt.scatter(plot_x, plot_y)\n",
    "    plt.text(plot_x+0.3, plot_y+0.3, df.columns[:-1][feature])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-144.99315218   -2.53299944]\n",
      " [ 477.39163882  -58.90186182]\n",
      " [ -91.869339    286.08178613]\n",
      " [-240.52914764 -224.64692488]]\n",
      "[105073.34576714  45261.62487597]\n",
      "[0.67444346 0.29052475]\n",
      "[0.67444346 0.96496821]\n"
     ]
    }
   ],
   "source": [
    "# PCA computation by sklearn\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)\n",
    "print(X_r)\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity: PCA Steps\n",
    "\n",
    "**In groups of 3:** Follow the steps here and write a function that computes the principle components for a dataset similar to the one we watched on YouTube: https://www.youtube.com/watch?v=0GzMcUy7ZI0 \n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Use the following matrix: `X = np.array([[1, 1, 1], [1, 2, 1], [1, 3, 2], [1, 4, 3]])`\n",
    "1. Subtract the column mean from the feature matrix -> this new matrix will be our centered matrix\n",
    "1. Calculate the covariance of the centered matrix (check out numpy's resources to see if there's a function that can do this for you...) --> this new matrix will be our covariance matrix.\n",
    "1. Calculate the eigenvalue and eigenvector of the covariance matrix. Remember how we did this in a previous activity!\n",
    "1. Sort the eigevalues so that they are in decresing order, and then find the top N (for example, 2) eigenvectors \n",
    "1. Dot multiply the centered matrix with the top N eigenvectors of the covariance matrix \n",
    "1. Compare the result of custom function with PCA in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Apply Principle to Boston housing features and then train the linear regression model \n",
    "\n",
    "- Basically, we remove correlation among features with PCA\n",
    "\n",
    "- We do not need to do feature data scaling (normalization) when we do PCA for features, because \n",
    "\n",
    "- Report the R-squared and MSE for a system with PCA+Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  PRICE  \n",
      "0     15.3  396.90   4.98   24.0  \n",
      "1     17.8  396.90   9.14   21.6  \n",
      "2     17.8  392.83   4.03   34.7  \n",
      "3     18.7  394.63   2.94   33.4  \n",
      "4     18.7  396.90   5.33   36.2  \n"
     ]
    }
   ],
   "source": [
    "# import the load_boston() function from sklearn.datasets\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "# print(boston.data)\n",
    "# print(boston.data.shape)\n",
    "\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.columns = boston.feature_names\n",
    "bos['PRICE'] = boston.target # our target value is price \n",
    "\n",
    "print(bos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the Inputs and Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = bos['PRICE']\n",
    "inputs = bos.drop(['PRICE'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.9</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "\n",
       "   PTRATIO      B  LSTAT  \n",
       "0     15.3  396.9   4.98  \n",
       "1     17.8  396.9   9.14  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Create a scaler object \n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit the inputs (calculate the mean and standard deviation feature-wise)\n",
    "# scaler = scaler.fit(inputs)\n",
    "# scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale the features and store them in a new variable (the actual scaling procedure)\n",
    "# inputs_scaled = scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.46234941 16.78872364 26.06035013 17.28190766 23.27677263 25.475109\n",
      " 17.25029736 27.36013067 24.83817934 18.36953785]\n",
      "[22.6 50.  23.   8.3 21.2 19.9 20.6 18.7 16.1 18.6]\n",
      "0.21039107665403312\n",
      "65.7471831055625\n"
     ]
    }
   ],
   "source": [
    "# Import module for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# split dataset into 75% training and 25% test          #x          #y                    #same sample of data\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, target, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(x_train)\n",
    "\n",
    "# Create a linear regression object\n",
    "reg = LinearRegression()\n",
    "# Fit the regression with the scaled TRAIN inputs and targets\n",
    "\n",
    "reg.fit(X_r, y_train)\n",
    "\n",
    "X_test_reduced = pca.transform(x_test)\n",
    "\n",
    "y_hat = reg.predict(X_test_reduced)\n",
    "\n",
    "print(y_hat[:10])\n",
    "print(y_test[:10].values)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "# print(pca.explained_variance_ratio_.cumsum())\n",
    "print(r2_score(y_test, y_hat))\n",
    "print(mean_squared_error(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit (conda)",
   "language": "python",
   "name": "python37664bitconda1ef9e08653c542229d6659c9d87d900d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
